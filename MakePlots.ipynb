{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_prediction import DataSplits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"predictions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weighted_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(sample1, sample2, w1, w2, n_iterations=100):\n",
    "    assert len(sample1) == len(w1)\n",
    "    assert len(sample2) == len(w2)\n",
    "    assert w1.ndim == w2.ndim == 1\n",
    "    assert sample1.ndim == sample2.ndim == 2\n",
    "    assert sample1.shape[1] == sample2.shape[1]\n",
    "\n",
    "    def single_iteration_(dummy):\n",
    "        del dummy\n",
    "        direction = np.random.normal(size=(1, sample1.shape[1]))\n",
    "        return weighted_ks.ks_2samp_w(\n",
    "                         (sample1 * direction).sum(axis=1),\n",
    "                         (sample2 * direction).sum(axis=1),\n",
    "                         w1, w2\n",
    "                     )\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:\n",
    "        result = max(executor.map(single_iteration_, range(n_iterations)))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_rich_mrartemev as utils_rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = utils_rich.raw_feature_columns\n",
    "Y_cols = utils_rich.dll_columns\n",
    "w_col  = utils_rich.weight_col\n",
    "pred_cols = [\"predicted_{}\".format(col) for col in Y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = dict()\n",
    "for particle, df in data.items():\n",
    "    all_dfs = dict(\n",
    "        real_train=(df.train[X_cols + Y_cols], df.train[w_col]),\n",
    "        real_val  =(df.val  [X_cols + Y_cols], df.val  [w_col]),\n",
    "        real_test =(df.test [X_cols + Y_cols], df.test [w_col]),\n",
    "        gen_train=(df.train[X_cols + pred_cols], df.train[w_col]),\n",
    "        gen_val  =(df.val  [X_cols + pred_cols], df.val  [w_col]),\n",
    "        gen_test =(df.test [X_cols + pred_cols], df.test [w_col])\n",
    "    )\n",
    "    print(particle)\n",
    "    distances[particle] = {\n",
    "        (s1, s2) : distance(df1.values, df2.values, w1.values, w2.values)\n",
    "        for (s1, (df1, w1)), (s2, (df2, w2)) in tqdm(combinations(all_dfs.items(), 2))\n",
    "    }\n",
    "    for k, v in distances[particle].items():\n",
    "        print(k, v)\n",
    "\n",
    "pd.to_pickle(distances, 'distances.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentile_range(array, weights, percentile, min_sumw=100):\n",
    "    if weights.sum() < min_sumw:\n",
    "        return array.min(), array.max()\n",
    "    ix = np.argsort(array)\n",
    "    array, weights = array[ix], weights[ix]\n",
    "    cdf = weights.cumsum()\n",
    "    cdf /= cdf[-1]\n",
    "    i_left_rev = np.argmax(cdf[::-1] < percentile)\n",
    "    i_right = np.argmax(cdf > 1. - percentile)\n",
    "    left = array[::-1][i_left_rev]\n",
    "    right = array[i_right]\n",
    "    return left, right\n",
    "\n",
    "def get_range(weights, *arrays, percentile=0.01):\n",
    "    lefts, rights = zip(\n",
    "        *[get_percentile_range(arr, weights, percentile) for arr in arrays]\n",
    "    )\n",
    "    return min(lefts), max(rights)\n",
    "\n",
    "def plot_hist_real_vs_gen(df, col, ax=None, selection=None, n_bins=None, linear=True):\n",
    "    predicted_col = \"predicted_{}\".format(col)\n",
    "\n",
    "    if selection is not None:\n",
    "        df = df[selection]\n",
    "    \n",
    "    real = df[col].values\n",
    "    gen  = df[predicted_col].values\n",
    "    w = df[utils_rich.weight_col].values\n",
    "\n",
    "    if n_bins is None:\n",
    "        n_bins = max(np.floor(w.sum()**0.5 / 4).astype(int), 4)\n",
    "    \n",
    "    bins = np.linspace(\n",
    "        *get_range(w, real, gen, percentile=0.01 if linear else 0.),\n",
    "        n_bins + 1\n",
    "    )\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    ax.hist(real, weights=w, bins=bins, label='real')\n",
    "    ax.hist(gen , weights=w, bins=bins, label='gen', alpha=0.5)\n",
    "    if not linear:\n",
    "        ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def make_bins_selection(df, bins_dict, cols=None):\n",
    "    if cols is None:\n",
    "        cols = [col for col in bins_dict.keys()]\n",
    "    \n",
    "    features = df[cols].values\n",
    "    \n",
    "    bins_nd = [bins_dict[col] for col in cols]\n",
    "    bins_left  = [[l for l in bins[:-1]] for bins in bins_nd]\n",
    "    bins_right = [[r for r in bins[1: ]] for bins in bins_nd]\n",
    "\n",
    "    shape = [len(bins) - 1 for bins in bins_nd]\n",
    "    shape.append(len(df))\n",
    "    \n",
    "    selection = np.array(\n",
    "        [(features >= lefts).all(axis=1) & (features <= rights).all(axis=1)\n",
    "         for lefts, rights in zip(product(*bins_left), product(*bins_right))]\n",
    "    )\n",
    "    selection_labels = np.array(\n",
    "        [['{:.3} <= {} <= {:.3}'.format(l, name, r) for name, l, r in zip(cols, lefts, rights)]\n",
    "         for lefts, rights in zip(product(*bins_left), product(*bins_right))]\n",
    "    )\n",
    "    selection_labels = selection_labels.reshape(*shape[:-1], -1)\n",
    "    selection = selection.reshape(shape)\n",
    "    return selection, selection_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantiles(arr, w, n):\n",
    "    ix = np.argsort(arr)\n",
    "    arr, w = arr[ix], w[ix]\n",
    "    cdf = w.cumsum()\n",
    "    cdf /= cdf[-1]\n",
    "    thresholds = np.arange(n + 1, dtype=float) / n\n",
    "    ids = np.argmax(cdf[:,np.newaxis] >= thresholds[np.newaxis,:], axis=0)\n",
    "    return arr[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_in_bins_2d(function, selection, labels,\n",
    "                    figsize=(15, 10),\n",
    "                    min_samples=50,\n",
    "                    fontsize=15,\n",
    "                    **params):\n",
    "    assert selection.ndim == 3\n",
    "    \n",
    "    fig, axxx = plt.subplots(selection.shape[0], selection.shape[1], figsize=figsize)\n",
    "    \n",
    "    for i_row, axx in enumerate(axxx):\n",
    "        for i_col, ax in enumerate(axx):\n",
    "            sel = selection[i_row, i_col]\n",
    "            if sel.sum() > min_samples:\n",
    "                function(**params, ax=ax, selection=sel)\n",
    "                ax.text(0.5, 1.0, labels[i_row][i_col][1],\n",
    "                        bbox={'facecolor':'white', 'pad':3},\n",
    "                        transform=ax.transAxes,\n",
    "                        horizontalalignment='center',\n",
    "                        fontsize=fontsize)\n",
    "                \n",
    "                ax.text(0.0, 0.5, labels[i_row][i_col][0],\n",
    "                        bbox={'facecolor':'white', 'pad':3},\n",
    "                        transform=ax.transAxes,\n",
    "                        verticalalignment='center',\n",
    "                        rotation='vertical',\n",
    "                        fontsize=fontsize)\n",
    "            else:\n",
    "                ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"patch.force_edgecolor\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = 'pdfs'\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kaon', 'pion', 'proton', 'muon'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "particles = ['pion', 'kaon', 'proton', 'muon']\n",
    "variables = ['RichDLLe', 'RichDLLk', 'RichDLLmu', 'RichDLLp', 'RichDLLbt']\n",
    "bin_cols = ['Brunel_P', 'Brunel_ETA']\n",
    "nbins = [8, 8]\n",
    "\n",
    "for particle in particles:\n",
    "    print(\"Working on:\", particle)\n",
    "    df = data[particle].test\n",
    "\n",
    "    bins_dict = {col : get_quantiles(df[col].values,\n",
    "                                     df[utils_rich.weight_col].values,\n",
    "                                     n)\n",
    "                 for col, n in zip(bin_cols, nbins)}\n",
    "\n",
    "    selection, labels = make_bins_selection(df, bins_dict, bin_cols)\n",
    "    \n",
    "    for variable in tqdm(variables):\n",
    "        fig = plot_in_bins_2d(plot_hist_real_vs_gen,\n",
    "                              selection[::-1],\n",
    "                              labels[::-1],\n",
    "                              figsize=(45, 45), df=df, col=variable)\n",
    "        file_name = \"{particle}_{target}_in_{y}_vs_{x}.pdf\".format(\n",
    "            particle=particle, target=variable,\n",
    "            y=bin_cols[0], x=bin_cols[1]\n",
    "        )\n",
    "        fig.savefig(os.path.join(output_dir, file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
